# SVM Fingerprint Models

LillyMol tool gfp_make can be used to generate an unlimited number of fingerprints.
Kernel based learners use similarity between training set members as the basis for learning.
The obvious step is to use the fingerprints generated by gfp_make as a kernel function in
an svm learner.

[gfp_make](/docs/Utilities/GFP_Tools/gfp_make.md)

For this work we use [svm lite](https://www.cs.cornell.edu/people/tj/svm_light). Note that
svm-lite does have specific licence requirements; please pay attention to that and make
sure that you are in compliance.

Theoretically other svm learners could have been used - when this was developed we
worked with both svm-lite and libsvm, but we first achieved good results with svm-lite.
Some have largely replicated this work by writing custom kernel functions for the svm learner in
scikit-learn, but at the expense of very slow model building.

## HowTo
Building an svmfp model requires two files

* train.smi
* train.activity

Both must be tabular, space separated files.

The smiles file might look like
```
C methane
CC etheane
```
and the activity file might look like
```
Id Activity
methane 1.234
ethane 0.922
```
For each identifier in the smiles file there must be an identifier and activity
entry in the `train.activity` file. Line ordering is not important.

Suggest using [activity_consistency](/docs/Molecule_Tools/activity_consistency.md)
in order to get a self consistent training set if duplicates are present.

## HowTo
Building a model, with the default fingerprints can be done via
```
svmfp_make.sh -mdir /path/to/model -A train.activity train.smi
```
where /path/to/model is a directory that will be created by the model
building. Safest would be to always build a new model directory.

Once the model is built, it can be used for scoring via
```
svmfp_evaluate.sh -mdir /path/to/model test.smi > test.pred
```
And the response in `test.pred` should be the same as what
was in `train.activity`.

To specity what fingerprint(s) are used in the model
```
svmfp_make.sh -gfp -EC3:AY -CATPS12 -RS -XLOGP -gfp -mdir /path/to/model -A train.activity train.smi
```
Note there is both an opening and closing `-gfp` option. Everything in between
those is passed unchanged to `gfp_make`.

Classification models are possible, but within this implementation, they have not
been extensively tested.

## Details
All  information needed for scoring the model is stored in the model
directory. The metadata is stored as a binary proto `model.dat` which
is also written in JSON form as `model.json`. The model scoring
tool only reads the binary file.

In the gfp tools, when multiple fingerprints are used, the overall similarity
is, bu default, an equally weighted sum of the similarities due to each
different fingerprint. In svmfp models, all fingerprints contribute bits
to a single overall fingerprint, and the origin of the bits is lost. So
there will be greater weight attached to fingerprints that set many bits.

In practice we find that combinations of fingerprints generate the most
useful models, and some fingerprints seem to generate better models than
others. Generally EC type fingerprints are probably the most powerful,
with proper atom typeing, and they combine well with CATS fingerprints
and Ring Substitution fingerprints.

A key determinant of model performance is the svm-lite cache size.
By default, we set this to 500MB, but if you have a larger dataset,
you can achieve significant performance boosts by increasing the
cache size. The largest cache size I have seen used is 8GB, which
reduced run time on a large set from 66 hours to 22 hours. At
Lilly we have implemented a parallel version, which can also 
provide meaningful speed-ups.

### clogp
For many models at Lilly we have found that converting BioByte clogp to a fingerprint
can provide significant boost to a model when combined with other fingerprints. For
many ADME type models where transport may be significant, this seems plausible. The implementation
is somewhat unusual. The computed value is discretised, but rather than have each
bucket set a separate bit, we instead use the discretised value as a count for a
counted fingerprint. 

If we had adopted the more traditional approach, a molecule with a clogp of 2.99 would
be completely different from one with a clogp of 3.01, which seems wrong. If the
value is used as a count, these molecules can become quite similar. By default
there are 10 bits set with the -CLOGP option, but that can be increased by
adding a digit to the option, `-CLOGP20` creates 20 bits, doulbling the influence
of clogp in the resulting kernel function.

Since BioByte is licensed software, we have found that our local implementation
of xlogp seems to work almost as well, and avoids licensing difficulties. Adding
`-XLOGP` will see 10 bits of discretised xlogp values added to the similarity
determination, and `-XLOGP20` will add twice that influence.
